{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from IPython.display import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.json') as fh:\n",
    "    vocab_obj = json.load(fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traduzco is not in vacab\n",
      "traduces is not in vacab\n",
      "traduzca is not in vacab\n",
      "traduzcas is not in vacab\n"
     ]
    }
   ],
   "source": [
    "words = ['traducir', 'traduce', 'traduzco', 'traduces', 'traduzca', 'traduzcas']\n",
    "for w in words:\n",
    "    if w not in vocab_obj['src_word2id']:\n",
    "        print('{0} is not in vacab'.format(w))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These words all carry the meaning of \"translate\", some of the variations do not make it to the 50,000 most frequent words in the vocabulary. the word-based NMT model will fail terribly when it encounters those that do not appear in the vocab. \n",
    "\n",
    "Character-aware NMT should be able to reconcile this issue, as all these variations have the same \"root\", i.e. \"tradu\", so the model might be able to infer the word given the first few characters of the word. Furthermode, the variations following the root might have similar prunonciations, for example \"z\" in \"traduzco\", \"traduzca\", and \"traduzcas\", and \"c\" in \"traduces\". This could be a pattern in Spanish words that the character-aware NMT should be able to learn from the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 (b) i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/financial_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/neuron_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Francisco_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/naturally_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/expectation_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 (b) ii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/char_financial_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/char_neuron_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/char_Francisco_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/char_naturally_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/char_expectation_nearest_neighbors.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 (b) iii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word-based embeddings are able to capture the word meanings (\"finaicial\": \"economic\"), whereas char-based embeddings seem to capture similarity of words based on how they spell (\"financial\": \"vertical\")\n",
    "\n",
    "For Word2Vec, we look at words that appear together, therefore words that co-occur frequently will become neighbors. Whereas CharCNN looks at how a word spells and learn how characters build up to words. Besides, the CharCNN model does not take into account nearby words at all. Therefore words that have similar spelling will become neighbors even though they have rather distinct meanings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path):\n",
    "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
    "    @param file_path (str): path to file containing corpus\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path):\n",
    "        sent = line.strip() #.split(' ')\n",
    "        data.append(sent)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentences = read_corpus('en_es_data/test.es')\n",
    "ref_translate = read_corpus('en_es_data/test.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8064"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_output = read_corpus('outputs/test_outputs_a4.txt')\n",
    "len(a4_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8064"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a5_output = read_corpus('outputs/test_outputs.txt')\n",
    "len(a5_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed_unks = [(idx, s) for idx, s in enumerate(a4_output) if '<unk>' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423,\n",
       " 'The colleagues on the journey of inanimate objects are not just the light that <unk> it, and the wind that goes on to the side and the heat of the room.')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embed_unks[209]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find one example where word-based model produced 'UNK', and char-based decoder produced an acceptable translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The colleagues on the journey of inanimate objects are not just the light that <unk> it, and the wind that goes on to the side and the heat of the room.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_output[423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The travel partners of the immediate objects are not just people -- it's also the light that shines it and the wind that goes around and the heat of the room.\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a5_output[423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Los compaeros de viaje de los objetos inanimados no son solo personas, tambin es la luz que lo alumbra y el viento que pasa a su lado y el calor de la habitacin.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_sentences[423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The fellow passengers for inanimate objects  are not just people,  but it's also the light shining on it  and the wind blowing past it and the heat of the room.\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_translate[423]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: The word-based embedding failed to translate \"shine\", but the char-based decoder manageed to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find one example where word-based model produced 'UNK', and char-based decoder produced an incorrect translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm here to talk to you about circles and <unk>\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_output[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm here today to talk to you about circles and epidemics.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a5_output[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hoy estoy aqu para hablarles sobre crculos y epifanas.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_sentences[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm here today to talk to you  about circles and epiphanies.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_translate[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: the 'UNK' corresponds to epifanas, which is a rare word. The char-based decoder mistakens it with the word \"epidemics\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
